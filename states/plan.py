import logging
import asyncio
import config
import json
import re
from typing import List, Dict, Any
from states.base import BaseState
from core.state import State
from core.context import ExecutionContext
from core import llm_service
from core.tool_registry import registry

logger = logging.getLogger("Delio.Plan")

class PlanState(BaseState):
    async def execute(self, context: ExecutionContext) -> State:
        logger.debug(f"ü§î Planning for user {context.user_id} (Actor-Critic Mode)")
        
        try:
            # 1. Build context-aware system instruction
            system_instruction = self._build_system_instruction(context)
            
            # 2. ACTOR PHASE (Gemini)
            preferred = context.metadata.get("preferred_model", "gemini")
            
            # Use new service adapter
            resp_text, model_used = await llm_service.call_actor(
                user_id=context.user_id,
                text=context.raw_input,
                system_instruction=system_instruction,
                preferred_model=preferred,
                image_path=context.metadata.get("image_path")
            )
            
            # 3. CRITIC PHASE (DeepSeek validation)
            if config.ENABLE_SYNERGY and "Error" not in model_used:
                validated_resp, synergy_label = await llm_service.call_critic(
                    user_query=context.raw_input,
                    actor_response=resp_text,
                    instruction=system_instruction
                )
                
                final_text = validated_resp
                context.metadata["model_used"] = synergy_label
            else:
                final_text = resp_text
                # Icon mapping
                icon = "‚ôä"
                if "pro" in model_used.lower(): icon = "üéì"
                elif "deepseek" in model_used.lower(): icon = "üêã"
                context.metadata["model_used"] = icon

            # 4. PARSE TOOL CALLS (JSON Extraction)
            # --- ROBUST JSON PARSER (Fix for "Regex Trap") ---
            try:
                # Find the first '{' and last '}'
                start_idx = final_text.find('{')
                end_idx = final_text.rfind('}')
                
                if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                    json_str = final_text[start_idx:end_idx+1]
                    # Sanitize common LLM mistakes (like trailing commas)
                    # For now, rely on stdlib, but could upgrade to json_repair
                    data = json.loads(json_str)
                    
                    if "tool_calls" in data:
                        context.tool_calls = data["tool_calls"]
                    else:
                        context.tool_calls = [] # Valid JSON but no tool calls
                else:
                    context.tool_calls = [] # No JSON found
                    
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è JSON Parse Error: {e}. Raw text: {final_text[:100]}...")
                context.tool_calls = [] # Fallback to text-only
            
            # Clean response text from JSON for display (optional, depending on UX)
            context.response = self._cleanup_response(final_text)

            # 5. Telemetry
            try:
                import telemetry
                telemetry.log_routing_event(
                    user_id=context.user_id,
                    life_level=context.metadata.get("life_level", "Unknown"),
                    complexity="Medium", 
                    model=context.metadata["model_used"],
                    in_txt=context.raw_input,
                    out_txt=context.response
                )
            except Exception as te:
                logger.warning(f"‚ö†Ô∏è Telemetry fail: {te}")
            
            # --- CONDITIONAL ROUTING ---
            
            # 1. Check for Critic Rejection
            synergy_label = context.metadata.get("model_used", "")
            # Route to ERROR only if it's a REAL rejection/error, NOT a simple API timeout
            if "‚ö†Ô∏è" in synergy_label and "(Timeout)" not in synergy_label:
                logger.warning(f"‚õî Plan Rejected by Critic. User: {context.user_id}")
                context.errors.append("Critic rejected the response (Potential Safety/Logic Issue)")
                return State.ERROR
            
            # 2. Check for Empty Response (if no tool calls)
            if not context.tool_calls and (not context.response or len(context.response.strip()) < 2):
                logger.warning(f"‚õî Plan Empty. User: {context.user_id}")
                context.errors.append("Actor produced empty response")
                return State.ERROR

            return State.DECIDE
            
        except Exception as e:
            logger.exception(f"‚ùå Error in PlanState: {e}")
            context.errors.append(str(e))
            return State.ERROR

    def _build_system_instruction(self, context: ExecutionContext) -> str:
        # (Same as before, keep consolidated)
        mem = context.memory_context
        instruction_parts = [
            f"–¢–∏ ‚Äî {config.yaml_config.get('bot', {}).get('name', 'Delio')}, –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∏–π AI-–∞—Å–∏—Å—Ç–µ–Ω—Ç (AID).",
            "–¢–∏ –ø—Ä–∞—Ü—é—î—à –∑–≥—ñ–¥–Ω–æ –∑—ñ —Å–≤–æ—î—é –∫–æ–Ω—Å—Ç–∏—Ç—É—Ü—ñ—î—é (FSM State Machine).\n",
            "### –í–ê–® –ü–†–û–§–Ü–õ–¨ –¢–ê –ö–û–ù–¢–ï–ö–°–¢ –ñ–ò–¢–¢–Ø:"
        ]
        
        structured = mem.get("structured_profile", {})
        for section, items in structured.items():
            if items:
                items_str = ", ".join([f"{k}: {v.get('value')}" for k, v in items.items()])
                instruction_parts.append(f"‚Ä¢ **{section.title()}**: {items_str}")
        
        memories = mem.get("long_term_memories", [])
        if memories:
            instruction_parts.append("\n### –í–ê–ñ–õ–ò–í–Ü –§–ê–ö–¢–ò –ó –ú–ò–ù–£–õ–ò–• –†–û–ó–ú–û–í:")
            for m in memories:
                instruction_parts.append(f"‚Ä¢ {m}")

        # --- TOOL DEFINITIONS ---
        tools = registry.get_definitions()
        if tools:
            instruction_parts.append("\n### –î–û–°–¢–£–ü–ù–Ü –Ü–ù–°–¢–†–£–ú–ï–ù–¢–ò (TOOLS):")
            instruction_parts.append("–Ø–∫—â–æ —Ç–æ–±—ñ –ø–æ—Ç—Ä—ñ–±–Ω–æ –≤–∏–∫–æ–Ω–∞—Ç–∏ –¥—ñ—é, –≤–∏–∫–ª–∏—á —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –ø–æ–≤–µ—Ä–Ω—É–≤—à–∏ JSON —É —Ñ–æ—Ä–º–∞—Ç—ñ:")
            instruction_parts.append("```json\n{\"tool_calls\": [{\"name\": \"tool_name\", \"arguments\": {\"arg1\": \"val1\"}}]}\n```")
            for t in tools:
                instruction_parts.append(f"- **{t['name']}**: {t['description']}")
                instruction_parts.append(f"  Params: {json.dumps(t['parameters'])}")

        # --- TOOL OUTPUTS (If returning from ACT) ---
        if context.tool_outputs:
            instruction_parts.append("\n### –†–ï–ó–£–õ–¨–¢–ê–¢–ò –í–ò–ö–û–ù–ê–ù–ù–Ø –Ü–ù–°–¢–†–£–ú–ï–ù–¢–Ü–í:")
            for output in context.tool_outputs:
                name = output.get("name")
                res = output.get("output") or output.get("error")
                instruction_parts.append(f"‚Ä¢ Tool '{name}': {res}")
            
            # Important: Clear tool_outputs or track them to avoid infinite reprocessing if not careful
            # Generally, we want to clear tool_calls so we don't re-execute them
            context.tool_calls = []

        # --- IMAGE CONTEXT ---
        if context.metadata.get("image_path"):
            instruction_parts.append("\n### [–°–ò–ì–ù–ê–õ: –ó–û–ë–†–ê–ñ–ï–ù–ù–Ø]")
            instruction_parts.append("–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á –Ω–∞–¥—ñ—Å–ª–∞–≤ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è. –ê–Ω–∞–ª—ñ–∑—É–π –π–æ–≥–æ –ø–µ—Ä—à–æ—á–µ—Ä–≥–æ–≤–æ —Ç–∞ –Ω–∞–¥–∞–π –¥–µ—Ç–∞–ª—å–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –æ—Å–Ω–æ–≤—ñ –≤—ñ–∑—É–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö.")
            instruction_parts.append("–§–û–†–ú–ê–¢ –í–Ü–î–ü–û–í–Ü–î–Ü (–û–ë–û–í'–Ø–ó–ö–û–í–û —Ä–æ–∑–¥—ñ–ª—è–π –ø–æ–¥–≤—ñ–π–Ω–∏–º –ø–µ—Ä–µ–Ω–æ—Å–æ–º —Ä—è–¥–∫–∞):")
            instruction_parts.append("1. [–ö–æ—Ä–æ—Ç–∫–∏–π –≤—ñ–∑—É–∞–ª—å–Ω–∏–π –æ–ø–∏—Å]")
            instruction_parts.append("\n\n2. [–¢–≤–æ—è —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è, —Ñ—ñ–ª–æ—Å–æ—Ñ—Å—å–∫–∏–π –∑–≤'—è–∑–æ–∫ –∞–±–æ —ñ–º–ø—Ä–æ–≤—ñ–∑–∞—Ü—ñ—è]")
            instruction_parts.append("\n\n3. [–ó–∞–∫–ª–∏–∫ –¥–æ –¥—ñ—ó –∞–±–æ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—á–Ω–∞ –ø–æ—Ä–∞–¥–∞]")
            
            if context.raw_input and "[IMAGE UPLOAD]" in context.raw_input:
                # If it's a raw upload without specific question beyond caption
                instruction_parts.append("–ú–µ—Ç–∞ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞: –î—ñ–∑–Ω–∞—Ç–∏—Å—å, —â–æ –Ω–∞ —Ñ–æ—Ç–æ —Ç–∞ –ø–æ—á—É—Ç–∏ —Ç–≤–æ—é –¥—É–º–∫—É.")

        # --- HEARTBEAT CONTEXT ---
        if context.event_type == "heartbeat":
            instruction_parts.append("\n### [–°–ò–ì–ù–ê–õ: HEARTBEAT CHECK-IN]")
            instruction_parts.append("–¶–µ–π –∑–∞–ø–∏—Ç —ñ–Ω—ñ—Ü—ñ–π–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ (Proactive Heartbeat). –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (—Ü—ñ–ª—ñ, —á–∞—Å, –Ω–∞–≥–∞–¥—É–≤–∞–Ω–Ω—è).")
            instruction_parts.append("1. –Ø–∫—â–æ —î —â–æ—Å—å –ö–†–ò–¢–ò–ß–ù–û –í–ê–ñ–õ–ò–í–ï –∞–±–æ –ö–û–†–ò–°–ù–ï (–Ω–∞–≥–∞–¥—É–≤–∞–Ω–Ω—è, –º–æ—Ç–∏–≤–∞—Ü—ñ—è, –ø–∏—Ç–∞–Ω–Ω—è –ø–æ —Ü—ñ–ª—ñ) ‚Äî –Ω–∞–ø–∏—à–∏ —Ü–µ.")
            instruction_parts.append("2. –Ø–∫—â–æ –Ω—ñ—á–æ–≥–æ –≤–∞–∂–ª–∏–≤–æ–≥–æ –Ω–µ–º–∞—î ‚Äî –ø—Ä–æ—Å—Ç–æ –≤–∏–≤–µ–¥–∏ —Å–ª–æ–≤–æ 'SKIP'.")
            instruction_parts.append("3. –ù–ï –≤—ñ—Ç–∞–π—Å—è, —è–∫—â–æ –≤ —Ü—å–æ–º—É –Ω–µ–º–∞—î –ø–æ—Ç—Ä–µ–±–∏. –ù–ï –ø–∏—à–∏ '–Ø–∫ —Å–ø—Ä–∞–≤–∏?', —è–∫—â–æ –Ω–µ–º–∞—î –∫–æ–Ω—Ç–µ–∫—Å—Ç—É.")
            instruction_parts.append("Bias towards SILENCE (SKIP). Speak only when valuable.")

        instruction_parts.append("\n### –¢–í–û–á –û–°–ù–û–í–ù–Ü –Ü–ù–°–¢–†–£–ö–¶–Ü–á:")

        # --- ACTIVE REFLECTION (Task-012) ---
        try:
            import sqlite3
            conn = sqlite3.connect('/root/ai_assistant/data/bot_data.db')
            cursor = conn.cursor()
            cursor.execute("""
                SELECT critique, correction FROM lessons_learned 
                WHERE user_id = ? AND score < 7 
                ORDER BY created_at DESC LIMIT 3
            """, (context.user_id,))
            lessons = cursor.fetchall()
            conn.close()
            
            if lessons:
                instruction_parts.append("\n### ‚ö†Ô∏è CRITICAL LEARNINGS FROM PAST MISTAKES:")
                for idx, (critique, correction) in enumerate(lessons):
                    instruction_parts.append(f"{idx+1}. Issue: {critique} -> Fix: {correction}")
                instruction_parts.append("DO NOT REPEAT THESE ERRORS.")
        except Exception:
            pass # Fail silently
        instruction_parts.append(config.SYSTEM_PROMPT)
        instruction_parts.append("\n" + config.TELEGRAM_STYLE)
        
        return "\n".join(instruction_parts)

    def _extract_tool_calls(self, text: str) -> List[Dict[str, Any]]:
        """Extracts tool calls from JSON blocks in the text."""
        try:
            # Look for JSON blocks
            json_blocks = re.findall(r"```json\s*(.*?)\s*```", text, re.DOTALL)
            if not json_blocks:
                # Try simple brace matching if no markdown blocks
                match = re.search(r"(\{.*\})", text, re.DOTALL)
                if match:
                    json_blocks = [match.group(1)]
            
            tool_calls = []
            for block in json_blocks:
                try:
                    data = json.loads(block)
                    if "tool_calls" in data:
                        tool_calls.extend(data["tool_calls"])
                except json.JSONDecodeError:
                    continue
            return tool_calls
        except Exception as e:
            logger.error(f"Error parsing tool calls: {e}")
            return []

    def _cleanup_response(self, text: str) -> str:
        """Removes JSON blocks from the response for cleaner output."""
        clean = re.sub(r"```json\s*(.*?)\s*```", "", text, flags=re.DOTALL).strip()
        # If it was just JSON, return a placeholder or empty
        return clean
