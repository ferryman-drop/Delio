from aiogram import Router, types, F
from aiogram.filters import Command
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton
import logging
import core
import config
import memory_manager
import memory
from core.fsm import FSMController
from core.state import State
from states.observe import ObserveState
from states.retrieve import RetrieveState
from states.plan import PlanState
from states.respond import RespondState
from states.memory_write import MemoryWriteState

router = Router()
logger = logging.getLogger(__name__)

# Initialize FSM (Single instance for the router)
fsm = FSMController()
fsm.register_handler(State.OBSERVE, ObserveState())
fsm.register_handler(State.RETRIEVE, RetrieveState())
fsm.register_handler(State.PLAN, PlanState())
# RESPOND needs bot, will be set per request or use a wrapper
fsm.register_handler(State.MEMORY_WRITE, MemoryWriteState())

@router.message(Command("start"))
async def cmd_start(message: types.Message):
    user_id = message.from_user.id
    # Reset context
    core.cache_context(user_id, [])
    
    # Get Telemetry Stats
    import sqlite3
    conn = memory_manager.MemoryController().get_connection()
    try:
        # Sum tokens and cost for this user
        row = conn.execute("SELECT SUM(input_tokens), SUM(output_tokens), SUM(cost_est) FROM routing_events WHERE user_id=?", (user_id,)).fetchone()
        in_tok, out_tok, cost = row
        in_tok = in_tok or 0
        out_tok = out_tok or 0
        cost = cost or 0.0
    except:
        in_tok, out_tok, cost = 0, 0, 0.0
    conn.close()

    # Check if synergy mode is enabled
    import config
    synergy_status = "üîÑ –ê–∫—Ç–∏–≤–Ω–∞" if config.ENABLE_SYNERGY else "‚è∏Ô∏è –í–∏–º–∫–Ω–µ–Ω–∞"
    
    msg = f"""ü§ñ Delio Assistant v3.0 ‚Äî –í–∞—à AI —Å—Ç—Ä–∞—Ç–µ–≥

üß† AI Stack:
 ‚Ä¢ Gemini 2.0 Flash ‚Äî —à–≤–∏–¥–∫—ñ—Å—Ç—å + reasoning
 ‚Ä¢ Gemini 2.5 Pro ‚Äî —Å–∫–ª–∞–¥–Ω—ñ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó (–∞–≤—Ç–æ–≤–∏–±—ñ—Ä)
 ‚Ä¢ DeepSeek V3 ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
 ‚Ä¢ –†–µ–∂–∏–º —Å–∏–Ω–µ—Ä–≥—ñ—ó: {synergy_status}
 ‚Ä¢ Adaptive Routing ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –≤–∏–±—ñ—Ä –º–æ–¥–µ–ª—ñ –∑–∞ Life Level

üìä –í–∞—à–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
 ‚Ä¢ –¢–æ–∫–µ–Ω—ñ–≤ –æ–ø—Ä–∞—Ü—å–æ–≤–∞–Ω–æ: {in_tok + out_tok:,}
 ‚Ä¢ –í–∞—Ä—Ç—ñ—Å—Ç—å: ${cost:.5f}
 ‚Ä¢ ID: {user_id}

‚ú® –ú–æ–∂–ª–∏–≤–æ—Å—Ç—ñ:
üó£Ô∏è –ì–æ–ª–æ—Å–æ–≤—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è ‚Äî —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è + –∞–Ω–∞–ª—ñ–∑ Gemini
üß† Memory V2 ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∞ –ø–∞–º'—è—Ç—å (Life Map, Goals, Contexts)
üéØ Interview Mode ‚Äî Time/Energy –ø—Ä–æ—Ñ–∞–π–ª
üïµÔ∏è Agent Analysis (/agent) ‚Äî –≥–ª–∏–±–æ–∫–∏–π —Ä–æ–∑–±—ñ—Ä –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π
üì∏ Snapshot ‚Äî –º–æ–º–µ–Ω—Ç–∞–ª—å–Ω–∏–π –∑–Ω—ñ–º–æ–∫ –ø–∞–º'—è—Ç—ñ
üí¨ Smart Context ‚Äî –∫–æ–º–ø—Ä–µ—Å—ñ—è —ñ—Å—Ç–æ—Ä—ñ—ó –¥—ñ–∞–ª–æ–≥—É
üîÑ Auto Model Selection ‚Äî Flash –¥–ª—è –ø—Ä–æ—Å—Ç–∏—Ö, Pro –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –∑–∞–¥–∞—á

üéõÔ∏è –ö–æ–º–∞–Ω–¥–∏:
 ‚Ä¢ /logic ‚Äî —Ä–µ–∂–∏–º –∞–Ω–∞–ª—ñ–∑—É Logic
 ‚Ä¢ /memory ‚Äî –ø–æ–¥–∏–≤–∏—Ç–∏—Å—å –ø–∞–º'—è—Ç—å V2
 ‚Ä¢ /interview ‚Äî –∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –ø—Ä–æ—Ñ—ñ–ª—å
 ‚Ä¢ /agent ‚Äî –∞–Ω–∞–ª—ñ–∑ –æ—Å—Ç–∞–Ω–Ω—å–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
 ‚Ä¢ /snapshot ‚Äî –∑–Ω—ñ–º–æ–∫ —Å—Ç–∞–Ω—É
 ‚Ä¢ /reset ‚Äî –æ—á–∏—Å—Ç–∏—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç

üëá –ü–∞–Ω–µ–ª—å –∫–µ—Ä—É–≤–∞–Ω–Ω—è:"""

    # Keyboard
    kb = ReplyKeyboardMarkup(keyboard=[
        [KeyboardButton(text="/logic"), KeyboardButton(text="/memory")],
        [KeyboardButton(text="/interview"), KeyboardButton(text="/start")]
    ], resize_keyboard=True)

    await message.answer(msg, reply_markup=kb)

@router.message(Command("memory"))
async def cmd_memory(message: types.Message):
    """Show detailed memory snapshot."""
    user_id = message.from_user.id
    
    # 1. Get Memory from V2 Controller
    from memory_manager_v2 import init_structured_memory, structured_memory
    
    if not structured_memory:
        import config
        init_structured_memory(config.DB_PATH)
        
    mem_data = structured_memory.get_all_memory(user_id)
    
    if not mem_data:
        await message.answer("üß† **Dimensions Empty**\nI haven't learned anything about you yet. Chat with me or use /interview!")
        return
        
    # 2. Format Output
    report = ["üè¢ **Delio Structure**"]
    
    # Emoji Map
    EMOJI_MAP = {
        "core_identity": "üë§ **Identity**",
        "life_level": "üìà **Life Level**",
        "time_energy": "‚è≥ **Resource State**",
        "skills_map": "üõ†Ô∏è **Skills & Tools**",
        "money_model": "üí∞ **Financial Model**",
        "goals": "üéØ **Active Goals**",
        "decision_patterns": "üß† **Decision Logic**",
        "behavior_discipline": "‚ö° **Habits & Discipline**",
        "trust_communication": "ü§ù **Communication Protocol**",
        "feedback_signals": "üí° **Feedback Loop**"
    }
    
    for section, items in mem_data.items():
        if not items:
            continue
            
        header = EMOJI_MAP.get(section, f"üìÅ **{section.title()}**")
        report.append(f"\n{header}")
        
        for key, data in items.items():
            val = data.get('value', 'N/A')
            conf = data.get('confidence', 0.0)
            
            # Formatting Date Keys (reported_202602012130 -> 01.02.2026)
            key_display = key
            if "reported_" in key:
                try:
                    # simplistic extraction if needed, or just "–ó–∞–ø–∏—Å"
                    key_display = key.replace("reported_", "–ó–∞–ø–∏—Å –≤—ñ–¥ ")
                except:
                    key_display = key

            # Formatting Value (Clean Strings)
            if isinstance(val, dict):
                # Flatten dict
                val_str = ", ".join([f"{k}: {v}" for k,v in val.items()])
                val_display = f" `{val_str}`"
            elif isinstance(val, list):
                val_str = "\n  ‚ñ™Ô∏è ".join([str(v) for v in val])
                val_display = f"\n  ‚ñ™Ô∏è {val_str}"
            else:
                val_display = f" `{val}`"

            # Confidence Indicator
            stats = ""
            if conf >= 0.8: stats = "‚úÖ"
            elif conf >= 0.5: stats = "‚ö†Ô∏è"
            else: stats = "‚ùì"

            report.append(f"‚ñ™Ô∏è *{key_display}* {val_display}")
    
    # Split & Send
    final_text = "\n".join(report)
    if len(final_text) > 4000:
        chunks = [final_text[i:i+4000] for i in range(0, len(final_text), 4000)]
        for chunk in chunks:
            await message.answer(chunk, parse_mode="Markdown")
    else:
        await message.answer(final_text, parse_mode="Markdown")

@router.message(Command("help"))
async def cmd_help(message: types.Message):
    msg = """**üìã –ö–æ–º–∞–Ω–¥–Ω–∏–π –¶–µ–Ω—Ç—Ä**

üîπ **/start** - –ü–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ú–µ–Ω—é
üîπ **/logic** - –ê–Ω–∞–ª—ñ–∑ –æ—Å—Ç–∞–Ω–Ω—å–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ (—á–æ–º—É —Ç–∞–∫?)
üîπ **/memory** - –ü–µ—Ä–µ–≥–ª—è–¥ –≤–∞—à–æ—ó –∫–∞—Ä—Ç–∏ –ø–∞–º'—è—Ç—ñ
üîπ **/interview** - –ü–æ—á–∞—Ç–∏ —ñ–Ω—Ç–µ—Ä–≤'—é (–∑–∞–ø–æ–≤–Ω–∏—Ç–∏ –ø—Ä–æ–≥–∞–ª–∏–Ω–∏)
üîπ **/snapshot** - –°—Ç–≤–æ—Ä–∏—Ç–∏ –±–µ–∫–∞–ø –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
üîπ **/reset** - –û—á–∏—Å—Ç–∏—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–æ–∑–º–æ–≤–∏ (–∑–∞–±—É—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—ñ 10 –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å). –î–æ–≤–≥–æ—Ç—Ä–∏–≤–∞–ª–∞ –ø–∞–º'—è—Ç—å –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è.
"""
    await message.answer(msg, parse_mode="Markdown")

@router.message(Command("logic"))
async def cmd_agent(message: types.Message):
    """Show details about the last AI response (Meta-Analysis)."""
    user_id = message.from_user.id
    import memory_manager
    conn = memory_manager.MemoryController().get_connection()
    try:
        # Get last routing event
        row = conn.execute("SELECT model_selected, complexity, life_level, cost_est, timestamp FROM routing_events WHERE user_id=? ORDER BY timestamp DESC LIMIT 1", (user_id,)).fetchone()
        
        if row:
            model, comp, level, cost, ts = row
            
            # Status determination
            status = "üü¢ Nominal"
            if "Error" in model: status = "üî¥ System Fault"
            if "Fallback" in model: status = "üü† Fallback Mode"
            
            msg = f"""üïµÔ∏è‚Äç‚ôÇÔ∏è **–ê–Ω–∞–ª—ñ–∑ –ê–≥–µ–Ω—Ç–∞**
            
**–°—Ç–∞—Ç—É—Å:** {status}
**–ß–∞—Å:** `{ts}`

üß† **–õ–æ–≥—ñ–∫–∞:**
‚Ä¢ **–°–∫–ª–∞–¥–Ω—ñ—Å—Ç—å:** `{comp}`
‚Ä¢ **–†—ñ–≤–µ–Ω—å –∂–∏—Ç—Ç—è:** `{level}`
‚Ä¢ **–ú–æ–¥–µ–ª—å:** `{model}`

üí∏ **–ï–∫–æ–Ω–æ–º—ñ–∫–∞:**
‚Ä¢ **–í–∞—Ä—Ç—ñ—Å—Ç—å:** `${cost:.6f}`

_–¶–µ —Ç–µ—Ö–Ω—ñ—á–Ω–∏–π –∑–≤—ñ—Ç –ø—Ä–æ —Ç–µ, —á–æ–º—É –±–æ—Ç –æ–±—Ä–∞–≤ —Å–∞–º–µ —Ç–∞–∫–∏–π —Å—Ç–∏–ª—å –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ._"""
        else:
            msg = "üö´ No interaction history found."
            
        await message.answer(msg, parse_mode="Markdown")
    except Exception as e:
        await message.answer(f"‚ùå Read Error: {e}")
    finally:
        conn.close()

@router.message(Command("interview"))
async def cmd_interview(message: types.Message):
    """Start interactive memory filling."""
    user_id = message.from_user.id
    import interviewer
    
    msg = await message.answer("üé§ **Interview Protocol Initiated...**")
    try:
        response = await interviewer.interviewer_instance.start_interview(user_id)
        await msg.edit_text(response, parse_mode="Markdown")
    except Exception as e:
        logger.error(f"Interview Error: {e}")
        await msg.edit_text(f"‚ùå **Interview Error:** `{e}`", parse_mode="Markdown")

@router.message(F.text)
async def handle_text(message: types.Message):
    user_id = message.from_user.id
    
    # Check for Active Interview
    import interviewer
    if interviewer.interviewer_instance.is_active(user_id):
        # Process answer intercept
        resp = await interviewer.interviewer_instance.process_answer(user_id, message.text)
        await message.answer(resp)  # No markdown parsing to avoid errors
        return

    # Deliver via FSM (Phase 1)
    fsm.register_handler(State.RESPOND, RespondState(message.bot))
    await fsm.process_event({
        "user_id": user_id,
        "type": "message",
        "text": message.text
    })

    # Legacy call (Keep commented for reference or remove)
    # await core.process_ai_request(message, message.text)

@router.message(F.voice)
async def handle_voice(message: types.Message):
    """
    Handle Voice Messages: Download -> Transcribe (Gemini) -> Clean (DeepSeek) -> Execute
    """
    import os
    import uuid
    
    # Download
    file_id = message.voice.file_id
    file = await message.bot.get_file(file_id)
    file_path = file.file_path
    
    temp_filename = f"/tmp/voice_{uuid.uuid4()}.ogg"
    
    try:
        await message.bot.download_file(file_path, temp_filename)
        
        # Transcribe (Legacy)
        import core as legacy_core
        raw_text = await legacy_core.transcribe_audio(temp_filename)
        if not raw_text:
             await message.answer("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –≥–æ–ª–æ—Å.")
             return
             
        # Process Refinement (Legacy)
        refined_text = await legacy_core.refine_text_with_deepseek(raw_text)
        await message.answer(f"üìù **–†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ —Ç–∞ –æ—á–∏—â–µ–Ω–æ:**\n\n{refined_text}")

        # Deliver via FSM
        fsm.register_handler(State.RESPOND, RespondState(message.bot))
        await fsm.process_event({
            "user_id": message.from_user.id,
            "type": "voice",
            "text": refined_text
        })
        
    except Exception as e:
        logger.error(f"Voice Error: {e}")
        await message.answer("‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è.")
    finally:
        # Cleanup
        if os.path.exists(temp_filename):
            os.remove(temp_filename)

@router.message(F.photo)
async def handle_photo(message: types.Message):
    # Vision logic
    await message.answer("üì∏ –§–æ—Ç–æ –≤ –ø—Ä–æ—Ü–µ—Å—ñ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–Ω—è.")
